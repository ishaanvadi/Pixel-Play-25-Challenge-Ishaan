{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Importing necessary libraries**"
      ],
      "metadata": {
        "id": "RXolpRWj6XZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbqy_ECi96g5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INSTALLING THE DATA**"
      ],
      "metadata": {
        "id": "ey5taCQj6jo8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUYWpF3s_L77"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taGYxdYj_NxD"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c vlg-recruitment-24-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqGfQ9KD_Pn6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile('/vlg-recruitment-24-challenge.zip','r')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATING TRAINING AND VALIDATION SETS**"
      ],
      "metadata": {
        "id": "Xur60Rcm60VP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHgNKePF_YI2"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/vlg-dataset/vlg-dataset/train',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/vlg-dataset/vlg-dataset/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing"
      ],
      "metadata": {
        "id": "Kc5lsEg26vEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJwMbcte_aX2"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)  # Normalize pixel values to [0,1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL BUILDING**"
      ],
      "metadata": {
        "id": "f3WbA2W27QA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6-MGia5_a9O"
      },
      "outputs": [],
      "source": [
        "# Get the number of classes from the train dataset\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "# Create the ResNet50 base model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = True\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create the classification head\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),  # L2 regularization\n",
        "    layers.Dropout(0.5),  # Dropout to reduce overfitting\n",
        "    layers.Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001))\n",
        "])\n",
        "\n",
        "data_cat=val_dataset.class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "DfBrpam17AWF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtnlHeMcAHNZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "\n",
        "# Define a learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return float(lr)  # Ensure returning as float\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))  # Explicitly cast to float\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Add ReduceLROnPlateau\n",
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',        # Watches validation loss\n",
        "    factor=0.5,                # Reduces learning rate by half\n",
        "    patience=3,                # Wait for 3 epochs without improvement\n",
        "    min_lr=1e-6,               # Minimum learning rate\n",
        "    verbose=1                  # Prints updates\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # Initial learning rate\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Include callbacks in training\n",
        "callbacks = [lr_scheduler, lr_reducer]\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks  # Add the updated callbacks list here\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GETTING THE LOW CONFIDENCE IMAGES**"
      ],
      "metadata": {
        "id": "3IsxwzTs7YQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59_svoMGQRI-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import shutil  # For moving files\n",
        "\n",
        "def classify_images(image_path):\n",
        "    input_image = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
        "    input_image_array = tf.keras.utils.img_to_array(input_image)\n",
        "    input_image_exp_dim = tf.expand_dims(input_image_array, 0)  # Batch dimension for model input\n",
        "\n",
        "    predictions = model.predict(input_image_exp_dim)\n",
        "    result = tf.nn.softmax(predictions[0])  # Convert logits to probabilities\n",
        "    outcome = data_cat[np.argmax(result)]  # Predicted class label\n",
        "    confidence = result[np.argmax(result)].numpy()  # Confidence score\n",
        "    return outcome, confidence\n",
        "\n",
        "# Directory containing the images\n",
        "image_dir = \"/vlg-dataset/vlg-dataset/test/\"\n",
        "\n",
        "# Directory to save low-confidence images\n",
        "new_folder = \"/data/low-confidence-images/\"\n",
        "os.makedirs(new_folder, exist_ok=True)\n",
        "\n",
        "# Path to save the CSV file\n",
        "csv_file = \"predict_above_threshold.csv\"\n",
        "\n",
        "# Create the CSV file\n",
        "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    # Write the header\n",
        "    writer.writerow([\"image_id\", \"class\"])\n",
        "\n",
        "    # Process each image in the directory\n",
        "    for image_name in os.listdir(image_dir):\n",
        "        if image_name.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")):  # Check for image file extensions\n",
        "            image_path = os.path.join(image_dir, image_name)\n",
        "            class_label, confidence_score = classify_images(image_path)\n",
        "\n",
        "            if confidence_score < 0.04:\n",
        "                # Move low-confidence images to the new folder\n",
        "                shutil.move(image_path, os.path.join(new_folder, image_name))\n",
        "            else:\n",
        "                # Log images with confidence >= 0.04 in the CSV without the confidence score\n",
        "                writer.writerow([image_name, class_label])\n",
        "\n",
        "print(f\"CSV file '{csv_file}' created for images with confidence >= 0.04.\")\n",
        "print(f\"Low-confidence images moved to '{new_folder}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ZERO SHOT LEARNING**"
      ],
      "metadata": {
        "id": "fP8YbE4x_zLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import cv2\n",
        "\n",
        "class AnimalDataset(data.dataset.Dataset):\n",
        "  def __init__(self, classes_file, transform):\n",
        "    predicate_binary_mat = np.array(np.genfromtxt('data/predicate-matrix-binary.txt', dtype='int'))\n",
        "    self.predicate_binary_mat = predicate_binary_mat\n",
        "    self.transform = transform\n",
        "\n",
        "    class_to_index = dict()\n",
        "    # Build dictionary of indices to classes\n",
        "    with open('data/classes.txt') as f:\n",
        "      index = 0\n",
        "      for line in f:\n",
        "        class_name = line.split('\\t')[0].strip()\n",
        "        class_to_index[class_name] = index\n",
        "        index += 1\n",
        "    self.class_to_index = class_to_index\n",
        "\n",
        "    img_names = []\n",
        "    img_index = []\n",
        "    with open('data/{}'.format(classes_file)) as f:\n",
        "      for line in f:\n",
        "        class_name = line.strip()\n",
        "        FOLDER_DIR = os.path.join('data/JPEGImages', class_name)\n",
        "        file_descriptor = os.path.join(FOLDER_DIR, '*.jpg')\n",
        "        files = glob(file_descriptor)\n",
        "\n",
        "        class_index = class_to_index[class_name]\n",
        "        for file_name in files:\n",
        "          img_names.append(file_name)\n",
        "          img_index.append(class_index)\n",
        "    self.img_names = img_names\n",
        "    self.img_index = img_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ECdS-4YnZ3eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, index):\n",
        "    im = Image.open(self.img_names[index])\n",
        "    if im.getbands()[0] == 'L':\n",
        "      im = im.convert('RGB')\n",
        "    if self.transform:\n",
        "      im = self.transform(im)\n",
        "    if im.shape != (3,224,224):\n",
        "      print(self.img_names[index])\n",
        "\n",
        "    im_index = self.img_index[index]\n",
        "    im_predicate = self.predicate_binary_mat[im_index,:]\n",
        "    return im, im_predicate, self.img_names[index], im_index\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n"
      ],
      "metadata": {
        "id": "xBUEEhzQ86US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Model Definition and Construction**\n"
      ],
      "metadata": {
        "id": "BQJi3On39U4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_labels, is_pretrained, is_parallel):\n",
        "    model = torchvision.models.resnet50(pretrained=is_pretrained).to(device)\n",
        "\n",
        "    if is_pretrained:\n",
        "        for i, param in model.named_parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    if is_parallel:\n",
        "        print('Using DataParallel:')\n",
        "        model = nn.DataParallel(model)\n",
        "        model_features = model.module.fc.in_features\n",
        "        model.module.fc = nn.Sequential(nn.BatchNorm1d(model_features), nn.ReLU(), nn.Dropout(0.25), nn.Linear(model_features, num_labels))\n",
        "    else:\n",
        "        print('Not using DataParallel:')\n",
        "        model_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(nn.BatchNorm1d(model_features), nn.ReLU(), nn.Dropout(0.25), nn.Linear(model_features, num_labels))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7660MUM7cJaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING LOOP"
      ],
      "metadata": {
        "id": "WIfEtqYe9h6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, eval_interval, learning_rate, output_filename, model_name, optimizer_name, batch_size):\n",
        "    # Parameters for train and test dataloaders\n",
        "    train_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 3}\n",
        "    test_params = {'batch_size': 1, 'shuffle': True, 'num_workers': 3}\n",
        "\n",
        "    # Define transforms\n",
        "    train_process_steps = transforms.Compose([\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "        transforms.Resize((224, 224)),  # ImageNet standard\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    test_process_steps = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "id": "DE2pwqVw5rb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and dataloaders\n",
        "    train_dataset = AnimalDataset('trainclasses.txt', train_process_steps)\n",
        "    test_dataset = AnimalDataset('testclasses.txt', test_process_steps)\n",
        "    train_loader = data.DataLoader(train_dataset, **train_params)\n",
        "    test_loader = data.DataLoader(test_dataset, **test_params)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    total_steps = len(train_loader)\n",
        "\n",
        "    # Build model (single or DataParallel)\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = build_model(num_labels, False, True).to(device)\n",
        "    else:\n",
        "        model = build_model(num_labels, False, False).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, features, img_names, indexes) in enumerate(train_loader):\n",
        "            if images.shape[0] < 2:  # Skip batch if size < 2 for BatchNorm\n",
        "                break\n",
        "            images = images.to(device)\n",
        "            features = features.to(device).float()\n",
        "            model.train()\n",
        "\n",
        "            outputs = model(images)\n",
        "            sigmoid_outputs = torch.sigmoid(outputs)\n",
        "            loss = criterion(sigmoid_outputs, features)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                curr_iter = epoch * len(train_loader) + i\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Batch Loss: {loss.item():.4f}')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # Periodic evaluation\n",
        "        if (epoch + 1) % eval_interval == 0:\n",
        "            print('Evaluating:')\n",
        "            curr_acc = evaluate(model, test_loader)\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}] Approx. training accuracy: {curr_acc}')"
      ],
      "metadata": {
        "id": "6tvv8S5g6Bni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation and Prediction Functions**"
      ],
      "metadata": {
        "id": "__IqXz189s45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final predictions and saving the model\n",
        "    print('Making predictions:')\n",
        "    if not os.path.exists('models'):\n",
        "        os.mkdir('models')\n",
        "    torch.save(model.state_dict(), f'models/{model_name}')\n",
        "    torch.save(optimizer.state_dict(), f'models/{optimizer_name}')\n",
        "    make_predictions(model, test_loader, output_filename)\n"
      ],
      "metadata": {
        "id": "b2ApUUY358fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    mean_acc = 0.0\n",
        "    pred_classes = []\n",
        "    truth_classes = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, features, img_names, indexes) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            features = features.to(device).float()\n",
        "            outputs = model(images)\n",
        "            sigmoid_outputs = torch.sigmoid(outputs)\n",
        "            pred_labels = sigmoid_outputs\n",
        "            curr_pred_classes = labels_to_class(pred_labels)\n",
        "            pred_classes.extend(curr_pred_classes)\n",
        "\n",
        "            curr_truth_classes = [classes[index] for index in indexes]\n",
        "            truth_classes.extend(curr_truth_classes)\n",
        "\n",
        "    pred_classes = np.array(pred_classes)\n",
        "    truth_classes = np.array(truth_classes)\n",
        "    mean_acc = np.mean(pred_classes == truth_classes)\n",
        "    model.train()  # Reset model to train mode\n",
        "    return mean_acc\n"
      ],
      "metadata": {
        "id": "GEek6lkI6DJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, dataloader, output_filename):\n",
        "    model.eval()\n",
        "    pred_classes = []\n",
        "    output_img_names = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, features, img_names, indexes) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            features = features.to(device).float()\n",
        "            outputs = model(images)\n",
        "            sigmoid_outputs = torch.sigmoid(outputs)\n",
        "            pred_labels = sigmoid_outputs\n",
        "            curr_pred_classes = labels_to_class(pred_labels)\n",
        "            pred_classes.extend(curr_pred_classes)\n",
        "            output_img_names.extend(img_names)\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(f'Prediction iter: {i}')\n",
        "\n",
        "    with open(output_filename, 'w') as f:\n",
        "        for i in range(len(pred_classes)):\n",
        "            output_name = output_img_names[i].replace('data/JPEGImages/', '')\n",
        "            f.write(f'{output_name} {pred_classes[i]}\\n')\n"
      ],
      "metadata": {
        "id": "LZhrvz4k6GTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Auxiliary Helper Functions**"
      ],
      "metadata": {
        "id": "z-HWjvoC93ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hamming_dist(curr_labels, class_labels):\n",
        "    return np.sum(curr_labels != class_labels)\n",
        "\n",
        "def get_cosine_dist(curr_labels, class_labels):\n",
        "    return np.sum(curr_labels * class_labels) / np.sqrt(np.sum(curr_labels)) / np.sqrt(np.sum(class_labels))\n",
        "\n",
        "def get_euclidean_dist(curr_labels, class_labels):\n",
        "    return np.sqrt(np.sum((curr_labels - class_labels)**2))\n"
      ],
      "metadata": {
        "id": "UDjFFkzZ6JzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_to_class(pred_labels):\n",
        "    predictions = []\n",
        "    for i in range(pred_labels.shape[0]):\n",
        "        curr_labels = pred_labels[i, :].cpu().detach().numpy()\n",
        "        best_dist = sys.maxsize\n",
        "        best_index = -1\n",
        "        for j in range(predicate_binary_mat.shape[0]):\n",
        "            class_labels = predicate_binary_mat[j, :]\n",
        "            dist = get_euclidean_dist(curr_labels, class_labels)\n",
        "            if dist < best_dist and classes[j] not in train_classes:\n",
        "                best_index = j\n",
        "                best_dist = dist\n",
        "        predictions.append(classes[best_index])\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "bwHrCg5c6MMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Loading and Debugging**\n"
      ],
      "metadata": {
        "id": "L-ker4sL99xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_file):\n",
        "    is_parallel = True  # torch.cuda.device_count() > 1\n",
        "    model = build_model(num_labels, False, is_parallel).to(device)\n",
        "    if is_parallel:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        dict = torch.load(model_file)\n",
        "        model = model.module\n",
        "        model.load_state_dict(dict)\n",
        "    else:\n",
        "        state_dict = torch.load(model_file)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "mC4FLKCb6OTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def debug(model_file, mode):\n",
        "    model = load_model(model_file)\n",
        "    test_params\n"
      ],
      "metadata": {
        "id": "vWhE7ccO_AK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MAIN FUNCTION**"
      ],
      "metadata": {
        "id": "2oT_mEQTAot4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  args = {\n",
        "    'num_epochs': 30,\n",
        "    'eval_interval': 5,\n",
        "    'learning_rate': 0.00001,\n",
        "    'model_name': 'model.bin',\n",
        "    'optimizer_name': 'optimizer.bin',\n",
        "    'output_file': 'predictions.txt',\n",
        "    'batch_size': 16,\n",
        "  }\n",
        "\n",
        "  num_epochs = args['num_epochs']\n",
        "  eval_interval = args['eval_interval']\n",
        "  learning_rate = args['learning_rate']\n",
        "  model_name = args['model_name']\n",
        "  optimizer_name = args['optimizer_name']\n",
        "  output_filename = args['output_file']\n",
        "  batch_size = args['batch_size']\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  train_classes = np.array(np.genfromtxt('data/trainclasses.txt', dtype='str'))\n",
        "  classes = np.array(np.genfromtxt('data/classes.txt', dtype='str'))\n",
        "  predicates = np.array(np.genfromtxt('data/predicates.txt', dtype='str'))\n",
        "  predicate_binary_mat = np.array(np.genfromtxt('data/predicate-matrix-binary.txt', dtype='int'))\n",
        "  predicate_continuous_mat = np.array(np.genfromtxt('data/predicate-matrix-continuous.txt', dtype='float'))\n",
        "  num_labels = len(predicates)\n",
        "\n",
        "  train(num_epochs, eval_interval, learning_rate, output_filename, model_name, optimizer_name, batch_size)\n",
        "\n",
        "  # Optional debugging:\n",
        "  # debug('models/model.bin', 'evaluate')\n"
      ],
      "metadata": {
        "id": "DxVuAiDeAr-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FINAL PREDICTIONS FROM SEEN+UNSEEN**"
      ],
      "metadata": {
        "id": "EwT5mtKtCgeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paths to the CSV files\n",
        "file1 = \"/data/predictions.csv\"\n",
        "file2 = \"/data/predict_above_threshold.csv\"\n",
        "\n",
        "# Read the CSV files\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "\n",
        "# Combine the two dataframes\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Path to save the combined CSV\n",
        "combined_csv_file = \"/data/combined_predictions.csv\"\n",
        "\n",
        "# Write the combined data to a new CSV file\n",
        "combined_df.to_csv(combined_csv_file, index=False)\n",
        "\n",
        "print(f\"Combined CSV file saved to '{combined_csv_file}'.\")"
      ],
      "metadata": {
        "id": "412bfCHoCfQ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
